# Model configuration
MODEL_NAME=llama-3.2-3b-instruct

# Server configuration
PORT=8080
MAX_MODEL_LEN=2048
TENSOR_PARALLEL_SIZE=8

